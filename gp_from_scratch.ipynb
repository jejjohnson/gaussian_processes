{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Algorithm from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import cholesky, cho_solve\n",
    "import sys\n",
    "sys.path.insert(0, '/home/emmanuel/Drives/erc/code/kernellib')\n",
    "sys.path.insert(0,'/Users/eman/Documents/code_projects/kernellib/')\n",
    "from kernellib.kernels import ard_kernel\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1) (11,) (51, 1)\n"
     ]
    }
   ],
   "source": [
    "# Training data is 11 points in [0,1] inclusive regularly spaced# Traini \n",
    "x_train = np.linspace(0, 1, 11).reshape(-1, 1)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "y_train = np.sin(x_train * (2 * np.pi)) + np.random.randn(x_train.shape[0], 1) * 0.2\n",
    "y_train = np.squeeze(y_train)\n",
    "\n",
    "x_test = np.linspace(0, 1, 51).reshape(-1, 1)\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'rbf'\n",
    "jitter = 1e-9\n",
    "random_state = 123\n",
    "\n",
    "init_signal_variance = 1.0\n",
    "init_length_scale = 1.0\n",
    "init_likelihood_variance = 0.1\n",
    "\n",
    "theta0 = np.array([init_signal_variance, \n",
    "                   init_likelihood_variance, \n",
    "                   init_likelihood_variance])\n",
    "bounds = ((1e-7, 1e7), (1e-7, 1e7), (1e-7, 1e7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import _check_length_scale\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "\n",
    "def ard_kernel(X, Y=None, length_scale=None, eval_gradient=False):\n",
    "    \n",
    "    # Determine if the kernel is isotropic or not\n",
    "    anisotropic = np.iterable(length_scale) and len(length_scale) > 1\n",
    "    \n",
    "    X = np.atleast_2d(X)\n",
    "    length_scale = _check_length_scale(X, length_scale)\n",
    "    \n",
    "    if Y is None:\n",
    "        dists = pdist(X / length_scale, metric='sqeuclidean')\n",
    "        K = np.exp(-.5 * dists)\n",
    "        # convert from upper-triangular matrix to square matrix\n",
    "        K = squareform(K)\n",
    "        np.fill_diagonal(K, 1)\n",
    "    else:\n",
    "        if eval_gradient:\n",
    "            raise ValueError(\n",
    "                \"Gradient can only be evaluated when Y is None.\")\n",
    "        dists = cdist(X / length_scale, Y / length_scale,\n",
    "                      metric='sqeuclidean')\n",
    "        K = np.exp(-.5 * dists)\n",
    "\n",
    "    if eval_gradient:\n",
    "\n",
    "        if not anisotropic or length_scale.shape[0] == 1:\n",
    "            K_gradient = \\\n",
    "                (K * squareform(dists))[:, :, np.newaxis]\n",
    "            return K, K_gradient\n",
    "        elif anisotropic:\n",
    "            # We need to recompute the pairwise dimension-wise distances\n",
    "            K_gradient = (X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2 \\\n",
    "                / (length_scale ** 2)\n",
    "            K_gradient *= K[..., np.newaxis]\n",
    "            return K, K_gradient\n",
    "    else:\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.linalg import cholesky, cho_solve, solve_triangular\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "from sklearn.gaussian_process.kernels import (_check_length_scale, \n",
    "                                              RBF, WhiteKernel, ConstantKernel)\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "\n",
    "class GaussianProcessRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, kernel='rbf', jitter=1e-10, random_state=None):\n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.jitter = jitter\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Initialize heuristics\n",
    "        self.signal_variance = 1.0\n",
    "        self.likelihood_variance = 0.1\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Check inputs\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        self.X_train_ = X\n",
    "        self.y_train_ = y\n",
    "        \n",
    "        # Determine Length_scale type\n",
    "        if self.kernel == 'rbf':\n",
    "            init_length_scale = 1.0\n",
    "        elif self.kernel == 'ard':\n",
    "            init_length_scale = np.ones(X.shape[1])\n",
    "        else:\n",
    "            raise ValueError('Unrecognised kernel.')\n",
    "            \n",
    "        # Initial HyperParameters\n",
    "        theta0 = np.array([self.signal_variance,\n",
    "                           self.likelihood_variance,\n",
    "                           init_length_scale])\n",
    "\n",
    "        bounds = ((1e-5, 1e5), (1e-5, 1e5), (1e-5, 1e5))\n",
    "\n",
    "        # Gradient Descent (Negative Log Marginal Likelihood)\n",
    "        best_params = minimize(self.neg_log_marginal_likelihood, \n",
    "                               x0=theta0, args=(), method='L-BFGS-B', \n",
    "                               bounds=bounds, jac=True)\n",
    "        print(best_params)\n",
    "        # Get the best parameters\n",
    "        self.signal_variance, self.length_scale, self.likelihood_variance = \\\n",
    "            self._get_hyperparams(best_params.x)\n",
    "\n",
    "        self.best_neg_log_likelihood = best_params.fun\n",
    "        self.marginal_likelihood = np.exp(-best_params.fun)\n",
    "\n",
    "        # Precompute Prediction quantities\n",
    "        print(self.length_scale, self.signal_variance, self.likelihood_variance)\n",
    "        \n",
    "        self.kernel_ = self.set_kernel(length_scale=self.length_scale,\n",
    "                                       signal_variance=self.signal_variance,\n",
    "                                       likelihood_variance=self.likelihood_variance)\n",
    "        \n",
    "        K = self.kernel_(self.X_train_)\n",
    "        \n",
    "        K[np.diag_indices_from(K)] += self.jitter\n",
    "        \n",
    "        \n",
    "        self.L_ = cholesky(K, lower=True)\n",
    "        \n",
    "        if self.y_train_.ndim == 1:\n",
    "            y_train = self.y_train_[:, np.newaxis]\n",
    "        \n",
    "        self.weights_ = cho_solve((self.L_, True), y_train.squeeze())\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_kernel(self, length_scale=None, \n",
    "                   signal_variance=None, \n",
    "                   likelihood_variance=None):\n",
    "        # Determine Kernel Type\n",
    "        if hasattr(self, 'length_scale'):\n",
    "            length_scale = self.length_scale\n",
    "        elif length_scale is None:\n",
    "            length_scale = 1.0\n",
    "        \n",
    "        if hasattr(self, 'signal_variance'):\n",
    "            signal_variance = self.signal_variance  \n",
    "        elif signal_variance is None:\n",
    "            signal_variance = 1.0\n",
    "        \n",
    "        if hasattr(self, 'likelihood_variance'):\n",
    "            likelihood_variance = self.likelihood_variance\n",
    "        elif likelihood_variance is None:\n",
    "            likelihood_variance = 0.1\n",
    "            \n",
    "        kernel = ConstantKernel(constant_value=signal_variance) \\\n",
    "                       * RBF(length_scale=length_scale) \\\n",
    "                       + WhiteKernel(noise_level=likelihood_variance)\n",
    "        return kernel\n",
    "    \n",
    "    def K(self, X, Y=None, length_scale=1.0, signal_variance=1.0, \n",
    "          likelihood_variance=0.01, eval_gradient=False):\n",
    "        \"\"\"Standard Kernel\n",
    "        \n",
    "        K(x, x) = nu * exp(||x-y||^2) + noise * delta\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, (n_samples x d_dimensions)\n",
    "        \n",
    "        Y : array, (n_samples x 1)\n",
    "        \n",
    "        length_scale : float, array (1) or (d_dimensions)\n",
    "        \n",
    "        signal_variance : float\n",
    "        \n",
    "        likelihood_variance : float\n",
    "        \n",
    "        eval_gradient : bool\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        \"\"\"\n",
    "        kernel = ConstantKernel(constant_value=signal_variance) \\\n",
    "                 * RBF(length_scale=length_scale) \\\n",
    "                 + WhiteKernel(noise_level=likelihood_variance)\n",
    "        \n",
    "        if eval_gradient:\n",
    "            return kernel(X, Y, eval_gradient=True)\n",
    "        else:\n",
    "            return kernel(X, Y)\n",
    "\n",
    "    def predict(self, X, return_std=False, return_cov=False):\n",
    "        \n",
    "        X = check_array(X)\n",
    "        \n",
    "        if not hasattr(self, \"X_train_\"):\n",
    "            raise ValueError('Not fitted yet...')\n",
    "        \n",
    "        K_trans = self.kernel_(X, self.X_train_)\n",
    "        \n",
    "        y_mean = np.dot(K_trans, self.weights_)\n",
    "        \n",
    "        if return_std:\n",
    "            \n",
    "            return y_mean, np.sqrt(self.predictive_variance(X, K_trans))\n",
    "        \n",
    "        elif return_cov:\n",
    "            \n",
    "            return y_mean, self.predictive_covariance(X, K_trans)\n",
    "        \n",
    "        else:\n",
    "            return y_mean\n",
    "    \n",
    "    def predictive_covariance(self, X, K_trans=None):\n",
    "        \n",
    "        X = check_array(X)\n",
    "        \n",
    "        if K_trans is None:\n",
    "            K_trans = self.kernel_(X, self.X_train_)\n",
    "            \n",
    "        v = cho_solve((self.L_, True), K_trans.T)\n",
    "        \n",
    "        covariance = self.kernel_(X) - np.dot(K_trans, v)\n",
    "        \n",
    "        return covariance\n",
    "    \n",
    "    def predictive_variance(self, X, K_trans=None):\n",
    "        \n",
    "        X = check_array(X)\n",
    "        \n",
    "        if K_trans is None:\n",
    "            K_trans = self.kernel_(X, self.X_train_)\n",
    "        \n",
    "        # Compute K_inv of K from it's cholesky decomposition\n",
    "        L_inv = solve_triangular(self.L_.T, np.eye(self.L_.shape[0]))\n",
    "        K_inv = np.dot(L_inv, L_inv.T)\n",
    "        \n",
    "        # Compute variance of predictive distribution\n",
    "        variance = self.kernel_.diag(X)\n",
    "        variance -= np.einsum(\"ij,ij->i\", np.dot(K_trans, K_inv), K_trans)\n",
    "        \n",
    "        # Check if any of the variances is negative because of\n",
    "        # numerical issues. If yes: set the variance to 0.\n",
    "        y_var_negative = variance < 0\n",
    "        if np.any(y_var_negative):\n",
    "            warnings.warn(\"Predicted variances smaller than 0. \"\n",
    "                          \"Setting those variances to 0.\")\n",
    "            variance[y_var_negative] = 0.0        \n",
    "        \n",
    "        return variance\n",
    "\n",
    "    def _get_hyperparams(self, theta):\n",
    "        \n",
    "        signal_variance = theta[0]\n",
    "        likelihood_variance = theta[1]\n",
    "        length_scale = theta[2:]\n",
    "        \n",
    "        return signal_variance, length_scale, likelihood_variance\n",
    "\n",
    "    def neg_log_marginal_likelihood(self, theta):\n",
    "\n",
    "        # Unpack theta parameters\n",
    "        signal_variance, length_scale, likelihood_variance = \\\n",
    "            self._get_hyperparams(theta)\n",
    "\n",
    "        # Get kernel\n",
    "        K, K_gradient = self.K(x_train, \n",
    "                               length_scale=length_scale,\n",
    "                               signal_variance=signal_variance,\n",
    "                               likelihood_variance=likelihood_variance,\n",
    "                               eval_gradient=True)\n",
    "\n",
    "        # Add the jitter term\n",
    "        K[np.diag_indices_from(K)] += self.jitter\n",
    "\n",
    "        # Solve\n",
    "        try:\n",
    "            L = cholesky(K, lower=True)\n",
    "        except np.linalg.LinAlgError:\n",
    "            return -np.inf, np.zeros_like(theta)\n",
    "\n",
    "        # multi-dimensional output of y_train\n",
    "        y_train = self.y_train_\n",
    "        \n",
    "        if y_train.ndim == 1:\n",
    "            y_train = y_train[:, np.newaxis]\n",
    "\n",
    "        weights = cho_solve((L, True), y_train)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Log likelihood\n",
    "        # -----------------------------\n",
    "        log_likelihood_dims = -0.5 * np.einsum(\"ik,ik->k\", y_train, weights)\n",
    "        log_likelihood_dims -= np.log(np.diag(L)).sum()\n",
    "        log_likelihood_dims -= (K.shape[0] / 2) * np.log(2 * np.pi)\n",
    "        log_likelihood = log_likelihood_dims.sum(-1)\n",
    "        \n",
    "        # ----------------------------\n",
    "        # Log Likelihood Gradient\n",
    "        # ----------------------------\n",
    "        prefactor = np.einsum(\"ik,jk->ijk\", weights, weights)\n",
    "        prefactor -= cho_solve((L, True), np.eye(K.shape[0]))[:, :, np.newaxis]\n",
    "\n",
    "        log_likelihood_gradient_dims = \\\n",
    "            0.5 * np.einsum(\"ijl,ijk->kl\", prefactor, K_gradient)        \n",
    "        log_likelihood_gradient = log_likelihood_gradient_dims.sum(-1)\n",
    "        \n",
    "        return -log_likelihood, -log_likelihood_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 16.399129139608583\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-0.397907  ,  3.53859578, -9.42126632])\n",
      "  message: b'ABNORMAL_TERMINATION_IN_LNSRCH'\n",
      "     nfev: 21\n",
      "      nit: 0\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([1. , 0.1, 1. ])\n",
      "[1.] 1.0 0.1\n"
     ]
    }
   ],
   "source": [
    "gp_model = GaussianProcessRegressor(kernel='rbf')\n",
    "\n",
    "gp_model.fit(x_train, y_train);\n",
    "y_pred = gp_model.predict(x_test)\n",
    "y_pred, y_err = gp_model.predict(x_test, return_std=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax_plot_sklearn(ax, y_pred, title):\n",
    "    \n",
    "    # get the condifence intervals\n",
    "    lower, upper = y_pred - y_err, y_pred + y_err\n",
    "    # plot the training data\n",
    "    ax.plot(x_train, y_train, 'r*')\n",
    "    \n",
    "    # plot the predictive mean\n",
    "    ax.plot(x_test, y_pred, 'b')\n",
    "    \n",
    "    # plot the confidence bounds\n",
    "    ax.fill_between(x_test.squeeze(), lower.squeeze(), upper.squeeze(), alpha=0.5, color='orange')\n",
    "    \n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca7f08d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(7,5))\n",
    "\n",
    "ax_plot_sklearn(ax, y_pred, 'Classical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
